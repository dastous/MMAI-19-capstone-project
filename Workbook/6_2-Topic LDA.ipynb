{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "#https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     og   hybrid pack strong punch name supposedly...\n",
       "1     aloha white widow especially potent cut white...\n",
       "2     sativa hybrid bred spain medical seed co bree...\n",
       "3     dawgs hybrid g chemdawg genetics bred canadia...\n",
       "4    kosher tangie k gold  indica hybrid combine le...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "documents=pd.read_excel(\"../CannaConnect/Dataset/description_clean.xlsx\")\n",
    "documents=documents.Description.astype(str)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2277x2245 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 76028 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.95,min_df=5, stop_words='english')  \n",
    "doc_term_matrix = count_vect.fit_transform(documents.values.astype('U'))\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=10, random_state=42)  \n",
    "LDA.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hold\n",
      "intended\n",
      "pre\n",
      "sandalwood\n",
      "fade\n",
      "bc\n",
      "vigorous\n",
      "fan\n",
      "tonic\n",
      "area\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):  \n",
    "    random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "    print(count_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chemdawg\n",
      "sativa\n",
      "sweet\n",
      "high\n",
      "aroma\n",
      "hybrid\n",
      "thc\n",
      "diesel\n",
      "cbd\n",
      "sour\n"
     ]
    }
   ],
   "source": [
    "first_topic = LDA.components_[0]\n",
    "top_topic_words = first_topic.argsort()[-10:]\n",
    "for i in top_topic_words:  \n",
    "    print(count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['chemdawg', 'sativa', 'sweet', 'high', 'aroma', 'hybrid', 'thc', 'diesel', 'cbd', 'sour']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['day', 'space', 'hybrid', 'citrus', 'aroma', 'lemon', 'genetics', 'seed', 'haze', 'sativa']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['best', 'hybrid', 'time', 'og', 'high', 'kush', 'place', 'indica', 'cannabis', 'cup']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['cooky', 'indica', 'body', 'aroma', 'og', 'hybrid', 'terpene', 'white', 'consumer', 'physical']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['week', 'sativa', 'aroma', 'cheese', 'flowering', 'bud', 'seed', 'hybrid', 'plant', 'indica']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['dream', 'indica', 'aroma', 'blueberry', 'sweet', 'seed', 'hybrid', 'blue', 'sativa', 'haze']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['genetics', 'aroma', 'bubba', 'sweet', 'body', 'bud', 'grape', 'indica', 'kush', 'purple']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['sativa', 'relief', 'hybrid', 'sweet', 'skunk', 'thc', 'indica', 'high', 'patient', 'pain']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8:\n",
      "['sweet', 'citrus', 'diesel', 'aroma', 'green', 'jack', 'bud', 'hybrid', 'orange', 'sativa']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9:\n",
      "['relaxing', 'alien', 'lemon', 'pain', 'aroma', 'hybrid', 'body', 'indica', 'kush', 'og']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):  \n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2277, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values = LDA.transform(doc_term_matrix)  \n",
    "topic_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF for Topic Modeling in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     og   hybrid pack strong punch name supposedly...\n",
       "1     aloha white widow especially potent cut white...\n",
       "2     sativa hybrid bred spain medical seed co bree...\n",
       "3     dawgs hybrid g chemdawg genetics bred canadia...\n",
       "4    kosher tangie k gold  indica hybrid combine le...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "documents=pd.read_excel(\"../CannaConnect/Dataset/description_clean.xlsx\")\n",
    "documents=documents.Description.astype(str)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(max_df=0.95, min_df=5, stop_words='english')  \n",
    "doc_term_matrix = tfidf_vect.fit_transform(documents.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=10, random_state=42, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=10, random_state=42)  \n",
    "nmf.fit(doc_term_matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mental\n",
      "conic\n",
      "scout\n",
      "set\n",
      "lsd\n",
      "nina\n",
      "le\n",
      "nearly\n",
      "bloom\n",
      "martian\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):  \n",
    "    random_id = random.randint(0,len(tfidf_vect.get_feature_names()))\n",
    "    print(tfidf_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = nmf.components_[0]  \n",
    "top_topic_words = first_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green\n",
      "dark\n",
      "bud\n",
      "granddaddy\n",
      "hue\n",
      "urkle\n",
      "deep\n",
      "indica\n",
      "grape\n",
      "purple\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:  \n",
    "    print(tfidf_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['green', 'dark', 'bud', 'granddaddy', 'hue', 'urkle', 'deep', 'indica', 'grape', 'purple']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['potent', 'kush', 'hybrid', 'cannabis', 'body', 'pine', 'sfv', 'indica', 'lemon', 'og']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['east', 'coast', 'uplifting', 'nyc', 'chemdawg', 'hybrid', 'fuel', 'sativa', 'sour', 'diesel']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['mango', 'spicy', 'uplifting', 'cerebral', 'lemon', 'jack', 'super', 'silver', 'sativa', 'haze']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['short', 'flavor', 'dj', 'sativa', 'sweet', 'hybrid', 'berry', 'blueberry', 'dream', 'blue']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['inflammation', 'took', 'ratio', 'content', 'place', 'cannabis', 'cup', 'high', 'thc', 'cbd']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['high', 'flower', 'yield', 'week', 'seed', 'flowering', 'skunk', 'indica', 'bud', 'plant']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['enjoy', 'body', 'sweet', 'terpene', 'cherry', 'scout', 'girl', 'physical', 'consumer', 'cooky']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8:\n",
      "['coat', 'euphoria', 'crystal', 'snow', 'alien', 'seed', 'resin', 'hybrid', 'widow', 'white']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9:\n",
      "['genetics', 'pain', 'body', 'pre', 'hindu', 'alien', 'master', 'indica', 'bubba', 'kush']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(nmf.components_):  \n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "#https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     og   hybrid strain pack strong punch name sup...\n",
       "1     aloha white widow especially potent cut white...\n",
       "2     sativa dominant hybrid bred spain medical see...\n",
       "3     dawgs hybrid g chemdawg genetics bred canadia...\n",
       "4    known kosher tangie k gold  indica dominant hy...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "documents=pd.read_excel(\"../CannaConnect/Dataset/description_clean.xlsx\")\n",
    "documents=documents.Description.astype(str)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2349x4265 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 86680 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')  \n",
    "doc_term_matrix = count_vect.fit_transform(documents.values.astype('U'))\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=10, random_state=42)  \n",
    "LDA.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brazilian\n",
      "internodal\n",
      "motivates\n",
      "lavender\n",
      "scout\n",
      "gorgeous\n",
      "bloom\n",
      "skunkiness\n",
      "stain\n",
      "ghost\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):  \n",
    "    random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "    print(count_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indica\n",
      "dominant\n",
      "cross\n",
      "thc\n",
      "aroma\n",
      "hybrid\n",
      "effect\n",
      "cbd\n",
      "cheese\n",
      "strain\n"
     ]
    }
   ],
   "source": [
    "first_topic = LDA.components_[0]\n",
    "top_topic_words = first_topic.argsort()[-10:]\n",
    "for i in top_topic_words:  \n",
    "    print(count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['indica', 'dominant', 'cross', 'thc', 'aroma', 'hybrid', 'effect', 'cbd', 'cheese', 'strain']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['consumer', 'aroma', 'dominant', 'body', 'cross', 'og', 'indica', 'effect', 'kush', 'strain']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['flavor', 'dominant', 'aroma', 'blue', 'sweet', 'indica', 'hybrid', 'effect', 'sativa', 'strain']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['hybrid', 'seed', 'herer', 'cross', 'nan', 'effect', 'jack', 'sativa', 'haze', 'strain']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['high', 'pineapple', 'durban', 'strain', 'poison', 'thc', 'scout', 'girl', 'cbd', 'cooky']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['berry', 'aroma', 'hybrid', 'sativa', 'green', 'haze', 'indica', 'bud', 'strain', 'purple']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['strawberry', 'dominant', 'indica', 'aroma', 'bud', 'hybrid', 'sweet', 'effect', 'sativa', 'strain']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['effect', 'indica', 'sativa', 'bud', 'sour', 'diesel', 'high', 'seed', 'hybrid', 'strain']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8:\n",
      "['cross', 'citrus', 'golden', 'aroma', 'sativa', 'hybrid', 'body', 'cherry', 'strain', 'effect']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9:\n",
      "['dominant', 'aroma', 'pain', 'cannabis', 'hybrid', 'effect', 'kush', 'indica', 'strain', 'og']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):  \n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2349, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values = LDA.transform(doc_term_matrix)  \n",
    "topic_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF for Topic Modeling in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     og   hybrid strain pack strong punch name sup...\n",
       "1     aloha white widow especially potent cut white...\n",
       "2     sativa dominant hybrid bred spain medical see...\n",
       "3     dawgs hybrid g chemdawg genetics bred canadia...\n",
       "4    known kosher tangie k gold  indica dominant hy...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "documents=pd.read_excel(\"../CannaConnect/Dataset/description_clean.xlsx\")\n",
    "documents=documents.Description.astype(str)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')  \n",
    "doc_term_matrix = tfidf_vect.fit_transform(documents.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=10, random_state=42, shuffle=False, solver='cd', tol=0.0001,\n",
       "  verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=10, random_state=42)  \n",
    "nmf.fit(doc_term_matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turkish\n",
      "vigor\n",
      "standard\n",
      "lift\n",
      "hydroponic\n",
      "real\n",
      "went\n",
      "nutrient\n",
      "shiskaberry\n",
      "season\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):  \n",
    "    random_id = random.randint(0,len(tfidf_vect.get_feature_names()))\n",
    "    print(tfidf_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = nmf.components_[0]  \n",
    "top_topic_words = first_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "produce\n",
      "sweet\n",
      "week\n",
      "flower\n",
      "plant\n",
      "strain\n",
      "bud\n",
      "kush\n",
      "indica\n",
      "purple\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:  \n",
    "    print(tfidf_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['produce', 'sweet', 'week', 'flower', 'plant', 'strain', 'bud', 'kush', 'indica', 'purple']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['finding', 'final', 'filter', 'film', 'filling', 'filled', 'file', 'finally', 'zoning', 'nan']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['potent', 'strain', 'body', 'pine', 'alien', 'sfv', 'indica', 'lemon', 'kush', 'og']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['cross', 'uplifting', 'effect', 'chemdawg', 'nyc', 'hybrid', 'fuel', 'sativa', 'sour', 'diesel']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['nd', 'strain', 'st', 'time', 'denver', 'competed', 'took', 'place', 'cannabis', 'cup']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['light', 'lemon', 'seed', 'skunk', 'strain', 'jack', 'silver', 'super', 'sativa', 'haze']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['effect', 'flavor', 'sweet', 'dominant', 'sativa', 'hybrid', 'berry', 'blueberry', 'dream', 'blue']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['cross', 'terpene', 'scout', 'cherry', 'girl', 'effect', 'consumer', 'physical', 'strain', 'cooky']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8:\n",
      "['level', 'patient', 'pain', 'strain', 'inflammation', 'ratio', 'content', 'high', 'thc', 'cbd']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9:\n",
      "['cross', 'skunk', 'alien', 'strawberry', 'dominant', 'resin', 'seed', 'hybrid', 'widow', 'white']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(nmf.components_):  \n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 9, 5, ..., 4, 2, 7], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values = nmf.transform(doc_term_matrix)  \n",
    "documents['Topic'] = topic_values.argmax(axis=1)  \n",
    "documents['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

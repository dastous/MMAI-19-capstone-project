{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Description</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>og   hybrid strain pack strong punch name sup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aloha white widow especially potent cut white...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sativa dominant hybrid bred spain medical see...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dawgs hybrid g chemdawg genetics bred canadia...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>known kosher tangie k gold  indica dominant hy...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                        Description  index\n",
       "0          0   og   hybrid strain pack strong punch name sup...      0\n",
       "1          1   aloha white widow especially potent cut white...      1\n",
       "2          2   sativa dominant hybrid bred spain medical see...      2\n",
       "3          3   dawgs hybrid g chemdawg genetics bred canadia...      3\n",
       "4          4  known kosher tangie k gold  indica dominant hy...      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_review=pd.read_excel(\"../CannaConnect/Dataset/description_clean.xlsx\")\n",
    "documents=df_review.astype(str)\n",
    "documents['index'] = documents.index\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dastous\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk import PorterStemmer\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['431']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 431].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [hybrid, strain, pack, strong, punch, supposed...\n",
       "1    [aloha, white, widow, especially, potent, whit...\n",
       "2    [sativa, dominant, hybrid, breed, spain, medic...\n",
       "3    [dawgs, hybrid, chemdawg, genetics, breed, can...\n",
       "4    [know, kosher, tangie, gold, indica, dominant,...\n",
       "5    [bear, mephisto, genetics, autoflowering, cros...\n",
       "6    [king, marijuana, strain, holy, trinity, headb...\n",
       "7    [indica, dominant, colorado, strain, breed, cr...\n",
       "8    [snoop, dogg, brand, line, cannabis, strain, c...\n",
       "9    [know, optimus, prime, indica, dominant, crazy...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['Description'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 alert\n",
      "1 body\n",
      "2 cerebral\n",
      "3 dark\n",
      "4 effect\n",
      "5 feel\n",
      "6 green\n",
      "7 high\n",
      "8 hollywood\n",
      "9 hybrid\n",
      "10 indica\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (5, 1),\n",
       " (8, 1),\n",
       " (12, 1),\n",
       " (24, 1),\n",
       " (26, 1),\n",
       " (38, 2),\n",
       " (46, 1),\n",
       " (47, 1),\n",
       " (50, 1),\n",
       " (57, 1),\n",
       " (67, 1),\n",
       " (87, 1),\n",
       " (91, 1),\n",
       " (98, 1),\n",
       " (112, 1),\n",
       " (128, 1),\n",
       " (226, 1),\n",
       " (229, 2),\n",
       " (234, 1),\n",
       " (382, 1),\n",
       " (409, 1),\n",
       " (425, 1),\n",
       " (452, 1),\n",
       " (474, 1),\n",
       " (603, 1),\n",
       " (655, 1),\n",
       " (714, 1),\n",
       " (879, 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[431]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 1 (\"body\") appears 1 time.\n",
      "Word 5 (\"green\") appears 1 time.\n",
      "Word 8 (\"indica\") appears 1 time.\n",
      "Word 12 (\"plant\") appears 1 time.\n",
      "Word 24 (\"tend\") appears 1 time.\n",
      "Word 26 (\"user\") appears 1 time.\n",
      "Word 38 (\"gold\") appears 2 time.\n",
      "Word 46 (\"mind\") appears 1 time.\n",
      "Word 47 (\"note\") appears 1 time.\n",
      "Word 50 (\"potent\") appears 1 time.\n",
      "Word 57 (\"taste\") appears 1 time.\n",
      "Word 67 (\"dominant\") appears 1 time.\n",
      "Word 87 (\"bring\") appears 1 time.\n",
      "Word 91 (\"citrus\") appears 1 time.\n",
      "Word 98 (\"relax\") appears 1 time.\n",
      "Word 112 (\"kush\") appears 1 time.\n",
      "Word 128 (\"cross\") appears 1 time.\n",
      "Word 226 (\"impressive\") appears 1 time.\n",
      "Word 229 (\"smell\") appears 2 time.\n",
      "Word 234 (\"california\") appears 1 time.\n",
      "Word 382 (\"look\") appears 1 time.\n",
      "Word 409 (\"sedative\") appears 1 time.\n",
      "Word 425 (\"hint\") appears 1 time.\n",
      "Word 452 (\"thing\") appears 1 time.\n",
      "Word 474 (\"think\") appears 1 time.\n",
      "Word 603 (\"cali\") appears 1 time.\n",
      "Word 655 (\"take\") appears 1 time.\n",
      "Word 714 (\"herb\") appears 1 time.\n",
      "Word 879 (\"clean\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_431 = bow_corpus[431]\n",
    "for i in range(len(bow_doc_431)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_431[i][0], \n",
    "                                               dictionary[bow_doc_431[i][0]], \n",
    "bow_doc_431[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.2531335733732363),\n",
      " (1, 0.07094739248780647),\n",
      " (2, 0.11428656528045983),\n",
      " (3, 0.18561165923205392),\n",
      " (4, 0.1756356026489178),\n",
      " (5, 0.12044217785439086),\n",
      " (6, 0.08664955273126615),\n",
      " (7, 0.04483905463259124),\n",
      " (8, 0.04757781100824252),\n",
      " (9, 0.17314376654352567),\n",
      " (10, 0.2322351021750598),\n",
      " (11, 0.08459730833331387),\n",
      " (12, 0.10840083271074967),\n",
      " (13, 0.12063929474332798),\n",
      " (14, 0.22832007728485829),\n",
      " (15, 0.2531335733732363),\n",
      " (16, 0.13934836976827145),\n",
      " (17, 0.24938705620081728),\n",
      " (18, 0.06088309927419281),\n",
      " (19, 0.2551015878750536),\n",
      " (20, 0.279648795111105),\n",
      " (21, 0.28962485169424107),\n",
      " (22, 0.2377777694084804),\n",
      " (23, 0.28610553977473613),\n",
      " (24, 0.18808228179143452),\n",
      " (25, 0.2571386694498781),\n",
      " (26, 0.20072131901580653)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=15, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.018*\"flower\" + 0.018*\"hybrid\" + 0.016*\"aroma\" + 0.014*\"indica\" + 0.014*\"sweet\" + 0.013*\"cross\" + 0.013*\"sativa\" + 0.011*\"seed\" + 0.010*\"cheese\" + 0.010*\"heavy\"\n",
      "Topic: 1 \n",
      "Words: 0.040*\"kush\" + 0.018*\"cross\" + 0.018*\"indica\" + 0.017*\"flower\" + 0.012*\"dominant\" + 0.012*\"strong\" + 0.011*\"aroma\" + 0.011*\"patient\" + 0.011*\"hybrid\" + 0.010*\"sativa\"\n",
      "Topic: 2 \n",
      "Words: 0.020*\"cross\" + 0.020*\"kush\" + 0.020*\"hybrid\" + 0.015*\"cooky\" + 0.015*\"aroma\" + 0.014*\"indica\" + 0.013*\"body\" + 0.012*\"dominant\" + 0.011*\"green\" + 0.010*\"girl\"\n",
      "Topic: 3 \n",
      "Words: 0.027*\"indica\" + 0.026*\"cross\" + 0.023*\"hybrid\" + 0.020*\"sour\" + 0.019*\"kush\" + 0.015*\"dominant\" + 0.015*\"aroma\" + 0.012*\"diesel\" + 0.011*\"genetics\" + 0.011*\"flavor\"\n",
      "Topic: 4 \n",
      "Words: 0.027*\"diesel\" + 0.019*\"indica\" + 0.017*\"cross\" + 0.017*\"aroma\" + 0.016*\"sour\" + 0.014*\"hybrid\" + 0.012*\"cannabis\" + 0.011*\"grow\" + 0.011*\"dominant\" + 0.010*\"flavor\"\n",
      "Topic: 5 \n",
      "Words: 0.022*\"sativa\" + 0.020*\"aroma\" + 0.018*\"kush\" + 0.016*\"cherry\" + 0.014*\"indica\" + 0.011*\"relax\" + 0.011*\"flavor\" + 0.011*\"genetics\" + 0.010*\"body\" + 0.010*\"mind\"\n",
      "Topic: 6 \n",
      "Words: 0.023*\"sativa\" + 0.021*\"kush\" + 0.017*\"aroma\" + 0.015*\"hybrid\" + 0.014*\"seed\" + 0.014*\"high\" + 0.013*\"sour\" + 0.012*\"cross\" + 0.011*\"diesel\" + 0.010*\"dominant\"\n",
      "Topic: 7 \n",
      "Words: 0.029*\"indica\" + 0.022*\"kush\" + 0.021*\"dominant\" + 0.018*\"sweet\" + 0.016*\"hybrid\" + 0.015*\"sativa\" + 0.012*\"blue\" + 0.011*\"body\" + 0.010*\"aroma\" + 0.010*\"breed\"\n",
      "Topic: 8 \n",
      "Words: 0.024*\"indica\" + 0.019*\"high\" + 0.017*\"sativa\" + 0.017*\"plant\" + 0.017*\"kush\" + 0.017*\"hybrid\" + 0.014*\"flower\" + 0.014*\"seed\" + 0.013*\"dominant\" + 0.013*\"cannabis\"\n",
      "Topic: 9 \n",
      "Words: 0.021*\"hybrid\" + 0.018*\"cross\" + 0.016*\"sativa\" + 0.016*\"sweet\" + 0.015*\"aroma\" + 0.014*\"flavor\" + 0.013*\"orange\" + 0.013*\"body\" + 0.010*\"genetics\" + 0.010*\"purple\"\n",
      "Topic: 10 \n",
      "Words: 0.033*\"haze\" + 0.017*\"cross\" + 0.016*\"body\" + 0.016*\"dominant\" + 0.014*\"sativa\" + 0.013*\"aroma\" + 0.013*\"indica\" + 0.013*\"hybrid\" + 0.012*\"consumer\" + 0.012*\"sweet\"\n",
      "Topic: 11 \n",
      "Words: 0.036*\"purple\" + 0.025*\"indica\" + 0.022*\"hybrid\" + 0.019*\"blue\" + 0.015*\"cross\" + 0.015*\"dominant\" + 0.015*\"sativa\" + 0.012*\"flavor\" + 0.011*\"flower\" + 0.011*\"body\"\n",
      "Topic: 12 \n",
      "Words: 0.025*\"indica\" + 0.018*\"sweet\" + 0.016*\"pain\" + 0.015*\"hybrid\" + 0.015*\"sativa\" + 0.014*\"high\" + 0.014*\"aroma\" + 0.014*\"dominant\" + 0.013*\"cross\" + 0.013*\"patient\"\n",
      "Topic: 13 \n",
      "Words: 0.029*\"hybrid\" + 0.019*\"cross\" + 0.018*\"sativa\" + 0.015*\"indica\" + 0.013*\"genetics\" + 0.012*\"body\" + 0.012*\"cannabis\" + 0.012*\"dominant\" + 0.010*\"consumer\" + 0.010*\"jack\"\n",
      "Topic: 14 \n",
      "Words: 0.021*\"strawberry\" + 0.018*\"sweet\" + 0.014*\"offer\" + 0.013*\"dominant\" + 0.013*\"cross\" + 0.012*\"body\" + 0.012*\"hybrid\" + 0.012*\"physical\" + 0.011*\"indica\" + 0.011*\"white\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.007*\"kush\" + 0.006*\"indica\" + 0.006*\"cherry\" + 0.006*\"white\" + 0.006*\"blue\" + 0.005*\"sativa\" + 0.005*\"hybrid\" + 0.005*\"dominant\" + 0.005*\"aroma\" + 0.005*\"pain\"\n",
      "Topic: 1 Word: 0.008*\"jack\" + 0.007*\"kush\" + 0.007*\"purple\" + 0.006*\"high\" + 0.006*\"sativa\" + 0.006*\"hybrid\" + 0.005*\"indica\" + 0.005*\"haze\" + 0.005*\"cannabis\" + 0.005*\"cross\"\n",
      "Topic: 2 Word: 0.011*\"haze\" + 0.008*\"sour\" + 0.008*\"sativa\" + 0.008*\"blue\" + 0.007*\"dream\" + 0.006*\"kush\" + 0.006*\"purple\" + 0.006*\"diesel\" + 0.006*\"genetics\" + 0.006*\"high\"\n",
      "Topic: 3 Word: 0.006*\"haze\" + 0.005*\"sativa\" + 0.005*\"purple\" + 0.005*\"flower\" + 0.005*\"kush\" + 0.005*\"indica\" + 0.005*\"strong\" + 0.005*\"black\" + 0.005*\"cooky\" + 0.005*\"widow\"\n",
      "Topic: 4 Word: 0.012*\"kush\" + 0.008*\"purple\" + 0.007*\"cooky\" + 0.007*\"indica\" + 0.006*\"bubba\" + 0.005*\"cannabis\" + 0.005*\"cross\" + 0.005*\"glue\" + 0.005*\"sweet\" + 0.005*\"body\"\n",
      "Topic: 5 Word: 0.009*\"white\" + 0.007*\"cheese\" + 0.007*\"kush\" + 0.007*\"indica\" + 0.006*\"diesel\" + 0.005*\"flower\" + 0.005*\"hybrid\" + 0.005*\"genetics\" + 0.005*\"pain\" + 0.005*\"sour\"\n",
      "Topic: 6 Word: 0.008*\"durban\" + 0.008*\"kush\" + 0.007*\"poison\" + 0.006*\"region\" + 0.006*\"dankness\" + 0.006*\"seed\" + 0.006*\"grow\" + 0.006*\"cannabis\" + 0.006*\"sativa\" + 0.005*\"world\"\n",
      "Topic: 7 Word: 0.008*\"haze\" + 0.007*\"lemon\" + 0.006*\"cannabis\" + 0.006*\"sativa\" + 0.006*\"dawg\" + 0.006*\"alien\" + 0.005*\"high\" + 0.005*\"kush\" + 0.005*\"genetics\" + 0.005*\"indica\"\n",
      "Topic: 8 Word: 0.007*\"sour\" + 0.007*\"orange\" + 0.006*\"indica\" + 0.006*\"kush\" + 0.005*\"breed\" + 0.005*\"blueberry\" + 0.005*\"body\" + 0.005*\"lime\" + 0.005*\"cross\" + 0.005*\"sativa\"\n",
      "Topic: 9 Word: 0.006*\"haze\" + 0.006*\"flower\" + 0.006*\"sativa\" + 0.005*\"high\" + 0.005*\"indica\" + 0.005*\"critical\" + 0.005*\"kush\" + 0.005*\"seed\" + 0.005*\"hybrid\" + 0.005*\"diesel\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indica',\n",
       " 'dominant',\n",
       " 'california',\n",
       " 'strain',\n",
       " 'think',\n",
       " 'take',\n",
       " 'hike',\n",
       " 'wood',\n",
       " 'clean',\n",
       " 'green',\n",
       " 'grass',\n",
       " 'smell',\n",
       " 'hint',\n",
       " 'herb',\n",
       " 'potent',\n",
       " 'smell',\n",
       " 'actually',\n",
       " 'thing',\n",
       " 'user',\n",
       " 'notice',\n",
       " 'cali',\n",
       " 'gold',\n",
       " 'taste',\n",
       " 'pull',\n",
       " 'note',\n",
       " 'citrus',\n",
       " 'bring',\n",
       " 'mind',\n",
       " 'lemongrass',\n",
       " 'strain',\n",
       " 'cross',\n",
       " 'kush',\n",
       " 'gold',\n",
       " 'plant',\n",
       " 'look',\n",
       " 'impressive',\n",
       " 'bulky',\n",
       " 'crystalline',\n",
       " 'effect',\n",
       " 'tend',\n",
       " 'body',\n",
       " 'relax',\n",
       " 'completely',\n",
       " 'sedative',\n",
       " 'hike',\n",
       " 'possibility']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[431]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9708315134048462\t \n",
      "Topic: 0.040*\"kush\" + 0.018*\"cross\" + 0.018*\"indica\" + 0.017*\"flower\" + 0.012*\"dominant\" + 0.012*\"strong\" + 0.011*\"aroma\" + 0.011*\"patient\" + 0.011*\"hybrid\" + 0.010*\"sativa\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[431]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.669053852558136\t \n",
      "Topic: 0.011*\"haze\" + 0.008*\"sour\" + 0.008*\"sativa\" + 0.008*\"blue\" + 0.007*\"dream\" + 0.006*\"kush\" + 0.006*\"purple\" + 0.006*\"diesel\" + 0.006*\"genetics\" + 0.006*\"high\"\n",
      "\n",
      "Score: 0.3059357702732086\t \n",
      "Topic: 0.007*\"kush\" + 0.006*\"indica\" + 0.006*\"cherry\" + 0.006*\"white\" + 0.006*\"blue\" + 0.005*\"sativa\" + 0.005*\"hybrid\" + 0.005*\"dominant\" + 0.005*\"aroma\" + 0.005*\"pain\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[431]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
